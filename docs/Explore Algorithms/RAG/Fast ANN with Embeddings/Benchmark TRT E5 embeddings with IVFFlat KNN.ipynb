{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39024b39-4055-4d57-8b2a-f5f578c3b955",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 1: Prepare Environment\n",
    "\n",
    "Import libraries and set logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a27d547-77bc-4016-98a0-23c0f99ebfd8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/tritonclient/grpc/__init__.py:56: UserWarning: Imported version of grpc is 1.51.0. There is a memory leak in certain Python GRPC versions (1.43.0 to be specific). Please use versions <1.43.0 or >=1.51.1 to avoid leaks (see https://github.com/grpc/grpc/issues/28513).\n  warnings.warn(\nINFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import mlflow\n",
    "import model_navigator as nav\n",
    "import torch\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from stnavigator import SentenceTransformerNavigator\n",
    "from utility import benchmarkGPU, generate_1M_data\n",
    "\n",
    "# Adjust logging levels\n",
    "logging.getLogger('py4j').setLevel(logging.ERROR)\n",
    "logging.getLogger(\"sentence_transformers\")\n",
    "logging.getLogger(\"sentence_transformers\").setLevel(logging.ERROR)\n",
    "mlflow.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a723bf86-7b58-44cc-9b97-ca4784c4ac79",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 2: Load public data\n",
    "\n",
    "In this notebook we will explore a dataset of fine food reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35ce7739-3fb6-4373-99be-dccd5f1d137e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_max = generate_1M_data(spark, \"wasbs://publicwasb@mmlspark.blob.core.windows.net/fine_food_reviews_1k.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91df647c-5d22-4e2f-9385-657fd0349ca8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 3: Set prediction model\n",
    "\n",
    "Set encoding using NVIDIA SentenceTransformerNavigator with TRT acceleration using Model Navigator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39dd6228-3a16-44b6-abd7-ee0ab908849b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = SentenceTransformerNavigator(\"intfloat/e5-large-v2\").eval()\n",
    "    model = nav.Module(model, name=\"e5-large-v2\")\n",
    "    model = model.to(device)\n",
    "    nav.load_optimized()\n",
    "\n",
    "    def predict(inputs):\n",
    "        with torch.no_grad():\n",
    "            output = model.encode(inputs.tolist(), convert_to_tensor=False, show_progress_bar=True)\n",
    "        return output\n",
    "    return predict\n",
    "\n",
    "encode = predict_batch_udf(predict_batch_fn, return_type=ArrayType(FloatType()), batch_size=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b29cd2a-310c-4293-aac2-ab540b545eb8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 4: Benchmark different scale of input data\n",
    "\n",
    "We will print duration of different stages of the experiment (SentanseTransformer NVIDIA TensorRT embedding with Rapids KNN)\n",
    "\n",
    "For example: [100, 1000, 10000, 100000] rows of text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6b128a6-75c4-4313-95dd-dc2ca482474d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********  Test TRT E5 with IVFlat KNN  ************\n\nScale 100 rows\n+---------------+--------------+\n|Benchmark Name |Duration (sec)|\n+---------------+--------------+\n|Embeddings     |25.47         |\n|KNN            |13.71         |\n|All stages     |39.18         |\n+---------------+--------------+\n\nScale 1000 rows\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "specified_values = [100, 1000, 10000, 100000]\n",
    "\n",
    "print(f\"********  Test TRT E5 with IVFlat KNN  ************\")\n",
    "print()\n",
    "\n",
    "for lim in specified_values:\n",
    "  benchmarkGPU(df_max, lim, encode)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Benchmark TRT E5 embeddings with IVFFlat KNN",
   "widgets": {}
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "save_output": true,
  "synapse_widget": {
   "state": {
    "4bd0e60b-98ae-4bfe-98ee-6f0399ceb456": {
     "persist_state": {
      "view": {
       "chartOptions": {
        "aggregationType": "count",
        "categoryFieldKeys": [
         "0"
        ],
        "chartType": "bar",
        "isStacked": false,
        "seriesFieldKeys": [
         "0"
        ]
       },
       "tableOptions": {},
       "type": "details"
      }
     },
     "sync_state": {
      "isSummary": false,
      "language": "scala",
      "table": {
       "rows": [
        {
         "0": "Once upon a time",
         "1": [
          " there was a girl who had a dream of becoming a writer.\n\nShe started writing short stories"
         ]
        },
        {
         "0": "Hello my name is",
         "1": [
          "***** and I have a question about my cat\n\nHello, thank you for bringing your question to"
         ]
        },
        {
         "0": "The best code is code thats",
         "1": [
          " not there\n\nCommenting your code is important. Not only does it help you remember what you"
         ]
        }
       ],
       "schema": [
        {
         "key": "0",
         "name": "prompt",
         "type": "string"
        },
        {
         "key": "1",
         "name": "text",
         "type": "ArrayType(StringType,true)"
        }
       ],
       "truncated": false
      }
     },
     "type": "Synapse.DataFrame"
    }
   },
   "version": "0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
